@article{Kabealo2023,
title = {A multi-firearm, multi-orientation audio dataset of gunshots},
journal = {Data in Brief},
volume = {48},
pages = {109091},
year = {2023},
issn = {2352-3409},
doi = {10.1016/j.dib.2023.109091},
author = {Ruksana Kabealo and Steven Wyatt and Akshay Aravamudan and Xi Zhang and David N. Acaron and Mawaba P. Dao and David Elliott and Anthony O. Smith and Carlos E. Otero and Luis D. Otero and Georgios C. Anagnostopoulos and Adrian M. Peter and Wesley Jones and Eric Lam},
keywords = {Gunshot audio classification, Audio forensics, Machine learning, Acoustic situational awareness, Multiple sensor orchestration, Internet of Battlefield Things (IoBT)},
abstract = {Early detection of firearm discharge has become increasingly critical for situational awareness in both civilian and military domains. The ability to determine the location and model of a discharged firearm is vital, as this can inform effective response plans. To this end, several gunshot audio datasets have been released that aim to facilitate gunshot detection and classification of a discharged firearm based on acoustic signatures. However, these datasets often suffer from a lack of variety in the orientations of recording devices around the source of the gunshot. Additionally, these datasets often suffer from the absence of proper time synchronization, which prevents the usage of these datasets for determining the Direction of Arrival (DoA) of the sound. In this paper, we present a multi-firearm, multi-orientation time-synchronized audio dataset collected in a semi-controlled real-world setting – providing us a degree of supervision – using several edge devices positioned in and around an outdoor firing range.}
}
